% Bibliography about static analysis (that doesn't fit in other bib files)





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Call graph construction
%%%

@Misc{Soles2023,
  author = 	 "Dakota Soles",
  title = 	 "An Empirical Study of Nondeterministic Behavior and Its Causes in Static Analysis Tools",
  howpublished = "ECOOP and ISSTA 2023 Student Research Competition",
  month = 	 jul,
  year = 	 2023,
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Other
%%%

@InProceedings{LiHZQ2023,
  author =       {Li, Haonan and Hao, Yu and Zhai, Yizhuo and Qian, Zhiyun},
  title =        {Assisting Static Analysis with Large Language Models: A {ChatGPT} Experiment},
  crossref =  {FSE2023},
  pages =     {2107-2111},
  numpages = 5,
  abstract =
      {Recent advances of Large Language Models (LLMs), e.g., ChatGPT, exhibited
    strong capabilities of comprehending and responding to questions across a
    variety of domains. Surprisingly, ChatGPT even possesses a strong
    understanding of program code. In this paper, we investigate where and how
    LLMs can assist static analysis by asking appropriate questions. In
    particular, we target a specific bug-finding tool, which produces many false
    positives from the static analysis. In our evaluation, we find that these
    false positives can be effectively pruned by asking carefully constructed
    questions about function-level behaviors or function
    summaries. Specifically, with a pilot study of 20 false positives, we can
    successfully prune 8 out of 20 based on GPT-3.5, whereas GPT-4 had a
    near-perfect result of 16 out of 20, where the four failed ones are not
    currently considered/supported by our questions, e.g., involving
    concurrency. Additionally, it also identified one false negative case (a
    missed bug). We find LLMs a promising tool that can enable a more effective
    and efficient program analysis.},
}




@InProceedings{ZhangPCT2023,
  author =       {Zhang, Huaien and Pei, Yu and Chen, Junjie and Tan, Shin Hwei},
  title =        {Statfier: Automated Testing of Static Analyzers via Semantic-Preserving Program Transformations},
  crossref =  {FSE2023},
  pages =     {237â€“249},
  abstract =  {Static analyzers reason about the behaviors of programs without executing them and report issues when they violate pre-defined desirable properties. One of the key limitations of static analyzers is their tendency to produce inaccurate and incomplete analysis results, i.e., they often generate too many spurious warnings and miss important issues. To help enhance the reliability of a static analyzer, developers usually manually write tests involving input programs and the corresponding expected analysis results for the analyzers. Meanwhile, a static analyzer often includes example programs in its documentation to demonstrate the desirable properties and/or their violations. Our key insight is that we can reuse programs extracted either from the official test suite or documentation and apply semantic-preserving transformations to them to generate variants. We studied the quality of input programs from these two sources and found that most rules in static analyzers are covered by at least one input program, implying the potential of using these programs as the basis for test generation. We present Statfier, a heuristic-based automated testing approach for static analyzers that generates program variants via semantic-preserving transformations and detects inconsistencies between the original program and variants (indicate inaccurate analysis results in the static analyzer). To select variants that are more likely to reveal new bugs, Statfier uses two key heuristics: (1) analysis report guided location selection that uses program locations in the reports produced by static analyzers to perform transformations and (2) structure diversity driven variant selection that chooses variants with different program contexts and diverse types of transformations. Our experiments with five popular static analyzers show that Statfier can find 79 bugs in these analyzers, of which 46 have been confirmed.},
}
