
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Macros bibliography
%%%


@TechReport{ellemtel92,
  author = 	 {{Ellemtel Telecommunication Systems Laboratory}},
  title = 	 {Programming in {C++}: Rules and Recommendations},
  institution =  {Ellemtel Telecommunications},
  year = 	 1992,
  address =	 {Sweden}
}


@Manual{cpp-manual,
  title = 	 {{GNU} {C} Preprocessor Manual},
  author =	 {{GNU~P}roject},
  edition =	 {v2.7.2}
}


@Manual{GCC,
  title = 	 "Using and Porting {GNU} {CC}",
  author = 	 "Richard M. Stallman",
  organization = "Free Software Foundation",
  address = 	 "Boston, MA, USA",
  edition = 	 "2.7.2",
  year = 	 1996,
  month = 	 jun # "~29,",
}


@Manual{Stallman97,
  title = 	 {{GNU} Coding Standards},
  author =	 {Richard Stallman},
  organization = {{GNU} Project},
  year =	 1997,
  month =	 {July},
  note =	 {\relax{}\url{ftp://prep.ai.mit.edu/pub/gnu/standards/standards.texi}}
}


@Misc{Deutsch90,
  author =	 {Deutsch, Peter},
  title =	 {ansi2knr},
  howpublished = {Freely available software program},
  year =	 1990,
  month =	 {December},
  note =	 {\relax{}Included in the ghostscript distribution from Aladdin
		  Enterprises, ftp://ftp.cs.wisc.edu/ghost/}
}


@Manual{Cannon90,
  title = 	 {Recommended {C} Style and Coding Standards},
  author =	 {Cannon, L.W. and Elliott, R.A. and Kirchoff, L.W. and Miller, J.H. and Mitze, R.W. and Schan, E.P. and Whittington, N.O. and Spencer, Henry and Keppel, David and Brader, Mark},
  edition =	 {6.0},
  year =	 1990,
  month =	 jun # "~25,"
}


@Manual{Dolenc90,
  title = 	 {Notes on Writing Portable Programs in {C}},
  author =	 {Dolenc, A. and Keppel, D. and Reilly, G. V.},
  edition =	 {8th Revision},
  year =	 1990,
  month =	 nov,
  note =         {\relax{}http://www.apocalypse.org/\discretionary{}{}{}pub/\discretionary{}{}{}u/\discretionary{}{}{}paul/\discretionary{}{}{}docs/\discretionary{}{}{}cport/\discretionary{}{}{}cport.htm}
}


@InProceedings(Murphy-icse18,
  author= 	"Murphy, Gail C. and Notkin, David and Lan, Erica S.-C.",
  title= 	"An empirical study of static call graph extractors",
  crossref= 	"ICSE96",
)


@book(Stroustrup-DesignEvolution,
  author=       "Stroustrup, Bjarne",
  title=        "The Design and Evolution of {C++}",
  publisher=    "Addison-Wesley",
  address =	"Reading, Massachusetts",
  year=         1994
)


@Book{CoxN91,
  author =	 "Brad J. Cox and Andrew J. Novobilski",
  title = 	 "Object Oriented Programming:  An Evolutionary Approach",
  publisher = 	 "Addison-Wesley",
  year = 	 1991,
  address =	 "Reading, Massachusetts"
}


@InProceedings(SiffR96,
  author= 	"Siff, Michael and Reps, Thomas",
  title= 	"Program generalization for software reuse: From {C} to {C++}",
  crossref =     "FSE96",
  pages= 	"135--146",
)


@InProceedings(OCallahan-icse97,
  author= 	"O'Callahan, Robert and Jackson, Daniel",
  title= 	"{Lackwit}: A program understanding tool based on type
                inference",
  crossref= 	"ICSE97",
  pages =        "338--348",
)


@Book{Carroll95,
  author = 	 {Carroll, Martin D. and Ellis, Margaret A.},
  title = 	 "Designing and Coding Reusable {C++}",
  publisher = 	 "Addison-Wesley",
  address =	 "Reading, Massachusetts",
  year = 	 1995
}


@Book{Harbison91,
  author = 	 "Harbison, Samuel P. and Guy L. {Steele Jr.}",
  title = 	 "{C}: A Reference Manual",
  publisher = 	 {Prentice-Hall},
  year = 	 1995,
  address =	 "Englewood Cliffs, New Jersey",
  edition =	 "Fourth"
}


@InProceedings(Evans-fse94,
  author= 	"Evans, David and Guttag, John and Horning, Jim and Tan, Yang Meng",
  title= 	"{LCLint}: A tool for using specifications to check code",
  crossref =     "FSE94",
  pages= 	"87--96",
)


@Manual{Evans:LCLint,
  title = 	 {{LCL}int User's Guide, Version 2.5},
  author =	 {David Evans},
  OPTorganization = {},
  OPTaddress = 	 {},
  year =	 2000,
  month =	 May,
  note =         {\url{http://lclint.cs.virginia.edu/guide/}}
}


@InProceedings{Krone94,
  author = 	 {Krone, Maren and Snelting, Gregor},
  title = 	 "On the Inference of Configuration Structures from Source Code",
  crossref =     "ICSE94",
  pages =	 {49--57},
}


@InProceedings{WeiseC93,
  author =       "Daniel Weise and Roger Crew",
  title = 	 "Programmable Syntax Macros",
  crossref =     "PLDI93",
  pages =        "156--165"
}


@TechReport{CppAwareCAnalyses,
  author = 	 {Badros, Greg and Notkin, David},
  title = 	 {A Framework for Preprocessor-Aware {C} Source Code Analyses},
  institution =  {University of Washington},
  year = 	 1998,
  number =	 {UW-CSE-98-08-04},
  address =	 {Seattle, Washington},
  month =	 {August}
}



@article{Badros00,
    author = "Greg J. Badros and David Notkin",
    title = "A framework for preprocessor-aware C source code analyses",
    journal = SPE,
    volume = "30",
    number = "8",
    pages = "907--924",
    year = "2000",
    url = "citeseer.nj.nec.com/badros98framework.html"
}


@InProceedings{GriswoldAM96,
  author = 	 "William G. Griswold and Darren C. Atkinson and Collin McCurdy",
  title = 	 "Fast, Flexible Syntactic Pattern Matching and Processing",
  booktitle = 	 "Proceedings of the IEEE 1996 Workshop on Program Comprehension",
  pages = 	 "144--153",
  year =	 1996,
  month =	 mar # "~29--31,",
  address = 	 "Berlin, Germany",
  abstract =
   "Program understanding can be assisted by tools that match patterns in the
    program source. Lexical pattern matchers provide excellent performance and
    ease of use, but have a limited vocabulary. Syntactic matchers provide more
    precision, but may sacrifice performance, retargetability, ease of use, or
    generality.
    \par
    To achieve more of the benefits of both models, we extend the pattern
    syntax of awk to support matching of abstract syntax trees, as demonstrated
    in a tool called tawk. Its pattern syntax is language-independent, based on
    abstract tree patterns. As in awk, patterns can have associated actions,
    which in tawk are written in C for generality, familiarity, and
    performance. The use of C is simplified by high-level libraries and dynamic
    linking. To allow processing of program files containing non-syntactic
    constructs, mechanisms have been designed that allow transparent matching
    in a syntactic fashion. So far, tawk has been retargeted to the MUMPS and C
    programming languages.
    \par
    We survey and apply prototypical approaches to concretely demonstrate the
    tradeoffs. Our results indicate that tawk can be used to quickly and easily
    perform a variety of common software engineering tasks, and the extensions
    to accommodate non-syntactic features significantly extend the generality
    of syntactic matchers."
}


@InProceedings{Crew97,
  author = 	 "Roger F. Crew",
  title = 	 "{ASTLOG}: a language for examining abstract syntax trees",
  booktitle =	 "Proceedings of the  USENIX Conference on Domain-Specific Languages",
  pages =	 "229--242",
  year =	 1997,
  address =	 "Santa Barbara, CA",
  month =	 oct
}


@Article{PaulP94,
  title =        "A framework for source code search using program
                 patterns",
  author =       "S. Paul and A. Prakash",
  journal =      "IEEE Transactions on Software Engineering",
  pages =        "463--475",
  volume =       "20",
  number =       "6",
  year =         "1994",
  sender =       "x@wins.uva.nl",
  class =        "Reverse_Engineering, Reverse_Design,
                 Fundamental_Methods_in_Reverse_Design,
                 Source_Code_Queries",
}







@Misc{Gimpel,
  author =	 "{Gimpel Software}",
  title =	 "{PC}-lint/{F}lexe{L}int",
  howpublished = "\url{http://www.gimpel.com/lintinfo.htm}",
  year =	 1999
}


@InProceedings{SpencerC92,
  author = 	 "Henry Spencer and Geoff Collyer",
  title = 	 "\#ifdef Considered Harmful, or Portability Experience with {C} {N}ews",
  crossref =     "USENIX92Summer",
  pages =	 "185--197",
  url = 	 "http://9www.x.bell-labs.com/user/geoff/ifdefs.ps.Z",
}


@TechReport{Johnson77,
  title =        "Lint, a {C} Program Checker",
  author =       "S. C. Johnson",
  type =         "Computing Science TR",
  number =       "65",
  month =        sep,
  year =         "1977",
  institution =  "Bell Labs",
  address =      "Murray Hill, NJ",
  keywords =     "CSTR",
  ignore-note =         "Updated version TM 78-1273-3",
}


@book{commonlisp:languagespec,
  title="Common Lisp: The Language",
  author="Guy L. {Steele Jr.}",
  publisher="Digital Press",
  address="Bedford, MA",
  note="Second edition",
  year=1990
}


@Article{Clinger91:R4RS,
  author =       "William Clinger and Jonathan A. Rees",
  title =        "The Revised\(^{4}\) Report on the Algorithmic Language
                 {S}cheme",
  journal =      "ACM LISP Pointers",
  volume =       "4",
  number =       "3",
  year =         "1991",
}


@Article{KelseyCR98,
  title = 	 "The Revised\(^{5}\) Report on the Algorithmic Language
                 {S}cheme",
  author = 	 "Richard Kelsey and William Clinger and Jonathan A. Rees",
  journal =      "ACM SIG{\-}PLAN Notices",
  volume =       33,
  number =       9,
  pages =        "26--76",
  month =        sep,
  year =         1998,
  coden =        "SINODQ",
  ISSN =         "0362-1340",
  bibdate =      "Tue Sep 15 17:01:28 1998",
  note =         "With H. Abelson, N. I. {Adams, IV}, D. H. Bartley, G.
                 Brooks, R. K. Dybvig, D. P. Friedman, R. Halstead, C.
                 Hanson, C. T. Haynes, E. Kohlbecker, D. Oxley, K. M.
                 Pitman, G. J. Rozas, G. L. {Steele, Jr.}, G. J.
                 Sussman, and M. Wand.",
  acknowledgement = ack-nhfb,
}


@InProceedings{lfp86*151,
  author =       "Eugene Kohlbecker and Daniel P. Friedman and Matthias
                 Felleisen and Bruce Duba",
  title =        "Hygienic Macro Expansion",
  pages =        "151--181",
  ISBN =         "0-89791-200-4",
  editor =       "Richard P. Gabriel",
  booktitle =    "Proceedings of the {ACM} Conference on {LISP} and
                 Functional Programming",
  address =      "Cambridge, MA",
  month =        aug,
  year =         "1986",
}


@Book{kicz91,
  author =       "Gregor Kiczales and Jim des Rivi\`{e}res and Daniel G.
                 Bobrow",
  title =        "The Art of the Metaobject Protocol",
  publisher =    "MIT Press",
  year =         "1991",
  entered-by =   "Andreas Paepcke",
  keywords =     "CLOS, MOP",
  comments =     "This is the official citation for the MOP spec. It can
                 also be used as a citation for an intro to the *idea*
                 of a MOP.",
}



@InProceedings{Favre96,
  author = 	 "Jean-Marie Favre",
  title = 	 "Preprocessors from an abstract point of view",
  booktitle = 	 "International Conference on Software Maintenance (ICSM'96)",
  year =	 1996,
  publisher =	 "IEEE Computer Society Press",
  address =	 "Monterey, California",
  month =	 nov # "~4--8,"
}


@InProceedings{Favre95,
  author = 	 "Jean-Marie Favre",
  title = 	 "The {CPP} paradox",
  booktitle = 	 "9th European Workshop on Software Maintenance",
  year =	 1995,
  address =	 "Durham, England",
  month =	 sep # "~25--27,"
}


@TechReport{SpulerS92,
  author = 	 "David A. Spuler and A. Sayed Muhammed Sajeev",
  title = 	 "Static detection of preprocessor macro errors in {C}",
  institution =  "James Cook University",
  year = 	 1992,
  number =	 "92/7",
  address =	 "Townsville, Australia",
  URL = 	 "http://www.cs.jcu.edu.au/ftp/pub/techreports/92-7.ps.gz",
}


@Unpublished{Lindig98:dagstuhl,
  author = 	 "Christian Lindig",
  title = 	 "Analysis of Software Variants",
  note = 	 "Talk at Schloss Dagstuhl Seminar on Program Comprehension
		  and Software Reengineering",
  year =	 1998,
  month =	 mar # "~9--13,"
}


@TechReport{lindig/98/tr-98-04,
  author =       "Christian Lindig",
  title =        "Analyse von Softwarevarianten",
  institution =  "TU Braunschweig, Institut f{\"u}r Programmiersprachen
                 und Informationssysteme, Abt. Softwaretechnologie",
  year =         "1998",
  type =         "Informatik-Bericht",
  number =       "98-04",
  address =      "D-38106 Braunschweig",
  month =        jan,
  annote =       "Software-Quelltexte werden oft durch den Einsatz eines
                 Pr{\"a}prozessors an verschiedenen Zielplattformen
                 angepa{\"s}t. Aus einem Quelltext entstehen dabei durch
                 den Pr{\"a}prozessor verschiedene Varianten der
                 Software, die einen Variantenverband bilden. Formale
                 Begriffsanalyse ist eine mathematische Theorie, mit
                 deren Hilfe der Variantenverband von Quelltexten
                 effizient bestimmt werden kann. Dar{\"u}berhinaus
                 k{\"o}nnen Redundanzen in der Beschreibung der
                 Variantenstruktur entdeckt und entfernt werden.",
}



@InProceedings{AtkinsBGM99,
  author = 	 "David Atkins and Thomas Ball and Todd Graves and Audris Mockus",
  title = 	 "Using Version Control Data to Evaluate the Impact of Software Tools",
  crossref = 	 "ICSE99",
  pages = 	 "324--333",
}


% This might be the right reference for the VE editor.




@Book{Zipf49,
  author =	 "George Kingsley Zipf",
  title = 	 "Human Behavior and the Principle of Least Effort",
  publisher = 	 "Addison-Wesley",
  year = 	 1949,
  address =	 "Cambridge, MA"
}


@InProceedings{ICCC::Salomon1996,
  title =        "Using Partial Evaluation in Support of Portability,
                 Reusability, and Maintainability",
  author =       "Daniel J. Salomon",
  booktitle =    "Compiler Construction, 6th International Conference",
  pages =        "208--222",
  editor =       "Tibor Gyimothy",
  address =      "Link{\"o}ping, Sweden",
  month =        "24--26~" # apr,
  year =         "1996",
  series =       "Lecture Notes in Computer Science",
  volume =       "1060",
  publisher =    "Springer",
  ISBN =         "ISBN 3-540-61053-7",
}


@Article{MeyersK97,
  author = 	 "Scott Meyers and Martin Klaus",
  title = 	 "Examining {C}++ program analyzers",
  journal = 	 "Dr.~Dobb's Journal",
  year = 	 1997,
  volume =	 22,
  number =	 2,
  pages =	 "68,70--2,74--5,87",
  month =	 feb
}


@Book{Meyers97,
  author =	 "Scott Meyers",
  title = 	 "Effective C++",
  publisher = 	 "Addison-Wesley",
  year = 	 1997,
  NEEDaddress = 	 "",
  edition =	 "second"
}


@InCollection{DavisDL90,
  author =	 "J.S. Davis and M.J. Davis and M.M. Law",
  title = 	 "Comparison of subjective entropy and user estimates of software complexity",
  booktitle = 	 "Empirical Foundations of Information and Software Science",
  publisher = 	 "V. Plenum",
  year = 	 1990,
  address =	 "New York, NY, USA"
}


@Misc{Lott-metrics-tools,
  author =	 "Christopher Lott",
  title =	 "Metrics collection tools for {C} and {C}++ Source Code",
  howpublished = "\url{http://www.cs.umd.edu/users/cml/cmetrics/}",
  year =	 1998
}


@InProceedings{Engblom99,
  author = 	 "Jakob Engblom",
  title = 	 "Static Properties of Commercial Embedded Real-Time
		  Programs, and Their Implication for Worst-Case Execution
		  Time Analysis",
  booktitle = 	 "Proceedings of the 5th IEEE Real-Time Technology and
		  Applications Symposium (RTAS '99)",
  OPTcrossref =  "",
  OPTkey = 	 "",
  OPTpages = 	 "",
  year = 	 "1999",
  OPTeditor = 	 "",
  OPTvolume = 	 "",
  OPTnumber = 	 "",
  OPTseries = 	 "",
  address = 	 "Vancouver, Canada",
  month = 	 jun,
  OPTorganization = "",
  OPTpublisher = "",
  OPTnote = 	 "",
  OPTannote = 	 ""
}


@InProceedings{McCloskeyB2005,
  author = 	 "Bill McCloskey and Eric Brewer",
  title = 	 "{ASTEC}: a new approach to refactoring {C}",
  crossref =     "FSE2005",
  pages =	 "21--30",
  abstract =
   "The C language is among the most widely used in the world, particularly for
    critical infrastructure software. C programs depend upon macros processed
    using the C preprocessor, but these macros are difficult to analyze and are
    often error-prone[4]. Existing tools that analyze and transform C source
    code have rudimentary support for the preprocessor, leading to obscure
    error messages and difficulty refactoring. We present a three part
    solution:  (1) a replacement macro language, ASTEC, that addresses the most
    important deficiencies of the preprocessor and that eliminates
    many of the errors it introduces; (2) a translator, MACROSCOPE, that
    converts existing code into ASTEC semi-automatically; and (3), an
    ASTEC-aware refactoring tool that handles preprocessor constructs
    naturally.
    \par
    ASTEC's primary benefits are its analyzability and its refactorability. We
    present several refactorings that are enabled by ASTEC. Additionally, ASTEC
    eliminates many of the sources of errors that can plague C preprocessor
    macros; Ernst et al.[4] estimate that more than 20\% of macros may contain
    errors. In this paper, we describe our translation and refactoring tools
    and evaluate them on a suite of programs including OpenSSH and the Linux
    kernel."
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Macro analysis and demacrofication
%%%




@INPROCEEDINGS{883045,
  author={Ying Hu and Merlo and Dagenais and Lague},
  booktitle={Proceedings 2000 International Conference on Software Maintenance},
  title={C/C++ conditional compilation analysis using symbolic execution},
  year={2000},
  volume={},
  number={},
  pages={196-206},
  abstract={Conditional compilation is one of the most powerful parts of a C/C++ environment available for building software for different platforms with different feature sets. Although conditional compilation is powerful, it can be difficult to understand and is error-prone. In large software systems, file inclusion, conditional compilation and macro substitution are closely related and are often largely interleaved. Without adequate tools, understanding complex header files is a tedious task. This practice may even be complicated as the hierarchies of header files grow with projects. This paper presents our experiences of studying conditional compilation based on the symbolic execution of preprocessing directives. Our two concrete goals are: for any given preprocessor directive or C/C++ source code line, finding the simplest sufficient condition to reach/compile it, and finding the full condition to reach/compile that code line. Two different strategies were used to achieve these two goals. A series of experiments conducted on the Linux kernel are presented.},
  keywords={C language},
  doi={10.1109/ICSM.2000.883045},
  ISSN={1063-6773},
  month={Oct},
}


@INPROCEEDINGS{1311050,
  author={Mennie, C.A. and Clarke, C.L.A.},
  booktitle={Proceedings. 12th IEEE International Workshop on Program Comprehension, 2004.},
  title={Giving meaning to macros},
  year={2004},
  volume={},
  number={},
  pages={79-85},
  abstract={With the prevalence of legacy C/C++ code, it continually becomes more important to address the issues of readability and maintainability. When considering the problems with refactoring or migrating C/C++ code we see how important a role preprocessor directives play. In part, because of these preprocessor directives it is extremely difficult to maintain our code. We outline a method of fact extraction and manipulation to create a set of transformations that remove preprocessor directives from the original source, converting them into regular C/C++ code with as few changes as possible, while maintaining readability in the code. In addition, we briefly explore some of the subtle issues that arise when migrating preprocessor directives. After discussing the general architecture of our test implementation, we look at some metrics gathered by running it on two software systems.},
  keywords={Computer science;Visualization;Computer architecture;Software testing;System testing;Software systems;Program processors},
  doi={10.1109/WPC.2004.1311050},
  ISSN={1092-8138},
  month={June},
}


@INPROCEEDINGS{6405259,
  author={Kumar, Aditya and Sutton, Andrew and Stroustrup, Bjarne},
  booktitle={2012 28th IEEE International Conference on Software Maintenance (ICSM)},
  title={Rejuvenating C++ programs through demacrofication},
  year={2012},
  volume={},
  number={},
  pages={98-107},
  abstract={We describe how legacy C++ programs can be rejuvenated using C++11 features such as generalized constant expressions, perfect forwarding, and lambda expressions. In general, this work develops a correspondence between different kinds of macros and the C++ declarations to which they should be transformed. We have created a set of demacrofication tools to assist a developer in the rejuvenation of C++ programs. To evaluate the work, we have applied the rejuvenation tools to a number of C++ libraries to assess the extent to which these libraries might be improved by demacrofication. Results indicate that between 68 and 98\% of potentially refactorable macros could be transformed into C++11 declarations. Additional experiments demonstrate why these numbers are not readily achieved using fully automated rejuvenation tools. We also discuss some techniques to further assist in automating rejuvenation process.},
  keywords={Libraries;Syntactics;Educational institutions;Intellectual property;Conferences;Software maintenance;source code rejuvenation;macros;C++11;refactoring;demacrofication},
  doi={10.1109/ICSM.2012.6405259},
  ISSN={1063-6773},
  month={Sep.},
}




@conference{icsoft07,
author={L{\'a}szl{\'o} Vid{\'a}cs and {\'{A}}rp{\'a}d Besz{\'e}des and Rudolf Ferenc},
authorASCII={Laszlo Vidacs and Arpad Beszedes and Rudolf Ferenc},
authorUTF={László Vidács and Árpád Beszédes and Rudolf Ferenc},
title={MACRO IMPACT ANALYSIS USING MACRO SLICING},
booktitle={Proceedings of the Second International Conference on Software and Data Technologies - Volume 2: ICSOFT,},
year={2007},
pages={230-235},
publisher={SciTePress},
organization={INSTICC},
doi={10.5220/0001341902300235},
isbn={978-989-8111-06-7},
}


@InProceedings{10.1007/11785477_19,
author="Siek, Jeremy
and Taha, Walid",
editor="Thomas, Dave",
title="A Semantic Analysis of C++ Templates",
booktitle="ECOOP 2006 -- Object-Oriented Programming",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="304--327",
abstract="Templates are a powerful but poorly understood feature of the C++ language. Their syntax resembles the parameterized classes of other languages (e.g., of Java). But because C++ supports template specialization, their semantics is quite different from that of parameterized classes. Template specialization provides a Turing-complete sub-language within C++ that executes at compile-time. Programmers put this power to many uses. For example, templates are a popular tool for writing program generators.",
isbn="978-3-540-35727-8"
}


@INPROCEEDINGS{5431774,
  author={Saebjoernsen, Andreas and Jiang, Lingxiao and Quinlan, Daniel and Su, Zhendong},
  booktitle={2009 IEEE/ACM International Conference on Automated Software Engineering},
  title={Static Validation of C Preprocessor Macros},
  year={2009},
  volume={},
  number={},
  pages={149-160},
  abstract={The widely used C preprocessor (CPP) is generally considered a source of difficulty for understanding and maintaining C/C++ programs. The main reason for this difficulty is CPP's purely lexical semantics, i.e., its treatment of both input and output as token streams. This can easily lead to errors that are difficult to diagnose, and it has been estimated that up to 20% of all macros are erroneous. To reduce such errors, more restrictive, replacement languages for CPP have been proposed to limit expanded macros to be valid C syntactic units. However, there is no practical tool that can effectively validate CPP macros in legacy applications. In this paper, we introduce a novel, general characterization of inconsistent macro usage as a strong indicator of macro errors. Our key insight is that all applications of the same macro should behave similarly. In particular, we map each macro call c in a source file f to c's normalized syntactic constructs within the abstract syntax tree (AST) for f's preprocessed source, and use syntactic similarity as the basis for comparing macro calls of the same macro definition. Utilizing this characterization, we have developed an efficient algorithm to statically validate macro usage in C/C++ programs. We have implemented the algorithm; evaluation results show that our tool is effective in detecting common macro-related errors and reports few false positives, making it a practical tool for validating macro usage.},
  keywords={Laboratories;Programming profession;Performance analysis;Software engineering;Computer languages;Engineering profession;Subcontracting;Government;Contracts;Research and development;preprossing;macro errors;inconsistencies},
  doi={10.1109/ASE.2009.75},
  ISSN={1938-4300},
  month={Nov},
}


@InProceedings{10.1007/978-3-319-09156-3_29,
author="D{\'e}vai, Rich{\'a}rd
and Vid{\'a}cs, L{\'a}szl{\'o}
and Ferenc, Rudolf
and Gyim{\'o}thy, Tibor",
editor="Murgante, Beniamino
and Misra, Sanjay
and Rocha, Ana Maria A. C.
and Torre, Carmelo
and Rocha, Jorge Gustavo
and Falc{\~a}o, Maria Irene
and Taniar, David
and Apduhan, Bernady O.
and Gervasi, Osvaldo",
title="Service Layer for IDE Integration of C/C++ Preprocessor Related Analysis",
booktitle="Computational Science and Its Applications -- ICCSA 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="402--417",
abstract="Software development in C/C++ languages is tightly coupled with preprocessor directives. While the use of preprocessor constructs cannot be avoided, current IDE support for developers can still be improved. Early feedback from IDEs about misused macros or conditional compilation has positive effects on developer productivity and code quality as well. In this paper we introduce a service layer for the Visual Studio to make detailed preprocessor information accessible for any type of IDE extensions. The service layer is built upon our previous work on the analysis of directives. We wrap the analyzer tool and provide its functionality through an API. We present the public interface of the service and demonstrate the provided services through small plug-ins implemented using various extension mechanisms. These plug-ins work together to aid the daily work of developers in several ways. We provide (1) an editor extension through the Managed Extensibility Framework which provides macro highlighting within the source code editor; (2) detailed information about actual macro substitutions and an alternative code view to show the results of macro calls; (3) a managed package for discovering the intermediate steps of macro replacements through a macro explorer. The purpose of this work is twofold: we present an additional layer designed to aid the work of tool developers; second, we provide directly usable IDE components to express its potentials.",
isbn="978-3-319-09156-3"
}


@INPROCEEDINGS{10011514,
  author={Malm, Jean and Enoiu, Eduard and Naser, Masud Abu and Lisper, Björn and Porkoláb, Zoltán and Eldh, Sigrid},
  booktitle={2022 48th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)},
  title={An Evaluation of General-Purpose Static Analysis Tools on C/C++ Test Code},
  year={2022},
  volume={},
  number={},
  pages={133-140},
  keywords={Industries;Codes;Sensitivity;Static analysis;Production;Manuals;Software;testing;static analysis;test maintenance;fault detection;code quality},
  doi={10.1109/SEAA56994.2022.00029}}




@InProceedings{10.1007/978-3-642-00722-4_9,
author="Padioleau, Yoann",
editor="de Moor, Oege
and Schwartzbach, Michael I.",
title="Parsing C/C++ Code without Pre-processing",
booktitle="Compiler Construction",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="109--125",
abstract="It is difficult to develop style-preserving source-to-source transformation engines for C and C++. The main reason is not the complexity of those languages, but the use of the C pre-processor (cpp), especially ifdefs and macros. This has for example hindered the development of refactoring tools for C and C++.",
isbn="978-3-642-00722-4"
}


@ARTICLE{10352114,
  author={Ning, Yuqiao and Zhang, Yanan and Ma, Chao and Guo, Zhen and Yu, Longhai},
  journal={IEEE Access},
  title={Empirical Study of Software Composition Analysis Tools for C/C++ Binary Programs},
  year={2024},
  volume={12},
  number={},
  pages={50418-50430},
  keywords={Libraries;Software;Codes;Cloning;Task analysis;Source coding;Benchmark testing;Software engineering;Binary program analysis;software composition analysis},
  doi={10.1109/ACCESS.2023.3341224}}


@inproceedings{10.1145/3196321.3196367,
author = {Gao, Qing and Ma, Sen and Shao, Sihao and Sui, Yulei and Zhao, Guoliang and Ma, Luyao and Ma, Xiao and Duan, Fuyao and Deng, Xiao and Zhang, Shikun and Chen, Xianglong},
title = {CoBOT: static C/C++ bug detection in the presence of incomplete code},
year = {2018},
isbn = {9781450357142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196321.3196367},
doi = {10.1145/3196321.3196367},
abstract = {To obtain precise and sound results, most of existing static analyzers require whole program analysis with complete source code. However, in reality, the source code of an application always interacts with many third-party libraries, which are often not easily accessible to static analyzers. Worse still, more than 30\% of legacy projects [1] cannot be compiled easily due to complicated configuration environments (e.g., third-party libraries, compiler options and macros), making ideal "whole-program analysis" unavailable in practice. This paper presents CoBOT [2], a static analysis tool that can detect bugs in the presence of incomplete code. It analyzes function APIs unavailable in application code by either using function summarization or automatically downloading and analyzing the corresponding library code as inferred from the application code and its configuration files. The experiments show that CoBOT is not only easy to use, but also effective in detecting bugs in real-world programs with incomplete code. Our demonstration video is at: https://youtu.be/bhjJp3e7LPM.},
booktitle = {Proceedings of the 26th Conference on Program Comprehension},
pages = {385–388},
numpages = {4},
keywords = {bug detection, incomplete code, static analysis},
location = {Gothenburg, Sweden},
series = {ICPC '18}
}



@article{VIDACS2009399,
title = {Combining preprocessor slicing with C/C++ language slicing},
author={L{\'a}szl{\'o} Vid{\'a}cs and {\'{A}}rp{\'a}d Besz{\'e}des and Tibor Gyim{\'o}thy},
authorASCII={Laszlo Vidacs and Arpad Beszedes and Tibor Gyimothy},
authorUTF={László Vidács and Árpád Beszédes and Tibor Gyimóthy},
journal = {Science of Computer Programming},
volume = {74},
number = {7},
pages = {399-413},
year = {2009},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2009.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167642309000355},
keywords = {Program slicing, C/C+, Preprocessing, Preprocessor slicing},
abstract = {Of the very few practical implementations of program slicing algorithms, the majority deal with C/C++ programs. Yet, preprocessor-related issues have been marginally addressed by these slicers, despite the fact that ignoring (or only partially handling) these constructs may lead to serious inaccuracies in the slicing results and hence in the program analysis task being performed. Recently, an accurate slicing method for preprocessor-related constructs has been proposed, which–when combined with existing C/C++ language slicers–can provide more complete slices and hence a more successful analysis of programs written in one of these languages. In this paper, we present our approach which combines the two slicing methods and, via practical experiments, describe its benefits in terms of the completeness of the resulting slices.}
}


@article{10.1145/333630.333633,
author = {Succi, Giancarlo and Wong, Raymond W.},
title = {The application of JavaCC to develop a C/C++ preprocessor},
year = {1999},
issue_date = {Fall 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
issn = {1559-6915},
url = {https://doi.org/10.1145/333630.333633},
doi = {10.1145/333630.333633},
abstract = {The commonly available software metrics-extraction tools for C/C++ depend on commercial preprocessors to preprocess the source file before being input into the analyzers. The following paper introduces a Java compiler generator called JavaCC and the application of the generator to develop a Java-based preprocessor for C/C++. Some technical features to the development of preprocessor are also mentioned, such as (1) handling of rescanning in preprocessing with LL(k) parsers, (2) managing conditional compiling with the state-based features of the lexical analyzer in JavaCC, and (3) resolving macro replacement and expansion with parsers.},
journal = {SIGAPP Appl. Comput. Rev.},
month = sep,
pages = {11–18},
numpages = {8}
}


@INPROCEEDINGS{1281408,
  author={Vidacs, L. and Beszedes, A. and Ferenc, R.},
  booktitle={Eighth European Conference on Software Maintenance and Reengineering, 2004. CSMR 2004. Proceedings.},
  title={Columbus schema for C/C++ preprocessing},
  year={2004},
  volume={},
  number={},
  pages={75-84},
  abstract={File inclusion, conditional compilation and macro processing has made the C/C++ preprocessor a powerful tool for programmers. However, program code with lots of directives often causes difficulties in program understanding and maintenance. The main source of the problem is the difference between the code that the programmer sees and the preprocessed code that the compiler gets. To aid program comprehension we designed a C/C++ preprocessor schema (supplementing the Columbus schema for C++) and implemented a preprocessor which produces both preprocessed files and schema instances. The instances of the schema may be used to model: (1) preprocessor constructs in the original source code, (2) the preprocessed compilation unit, and (3) the transformations made by the preprocessor.},
  keywords={Programming profession;Program processors;Visualization;Software maintenance;Software tools;Software engineering;Concrete;Information analysis;Application software;Quality assurance},
  doi={10.1109/CSMR.2004.1281408},
  ISSN={1534-5351},
  month={March},
}






@article{WADDINGTON200764,
title = {High-fidelity C/C++ code transformation},
journal = {Science of Computer Programming},
volume = {68},
number = {2},
pages = {64-78},
year = {2007},
note = {Special Issue on ETAPS 2005 Workshop on Language Descriptions, Tools, and Applications (LDTA ’05)},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2006.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0167642307000718},
author = {Daniel Waddington and Bin Yao},
keywords = {Source transformation, High-fidelity, Preprocessing},
abstract = {As software systems become increasingly massive, the advantages of automated transformation tools are clearly evident. These tools allow the machine to both reason about and manipulate high-level source code. They enable off-loading of mundane and laborious programming tasks from human developer to machine, thereby reducing cost and development time frames. Although there has been much work in software transformation, there still exist many hurdles in realizing this technology in a commercial domain. From our own experience, there are two significant problems that must be addressed before transformation technology can be usefully applied in a commercial setting. These are: (1) Avoiding disruption of the style (i.e., layout and commenting) of source code and the introduction of any undesired modifications that can occur as a side effect of the transformation process. (2) Correct automated handling of C preprocessing and the presentation of a semantically correct view of the program during transformation. Many existing automated transformation tools require source to be manually modified so that preprocessing constructs can be parsed. The real semantic of the program remains obscured resulting in the need for complicated analysis during transformation. Many systems also resort to pretty printing to generate transformed programs, which inherently disrupts coding style. In this paper we describe our own C/C++ transformation system, Proteus, that addresses both these issues. It has been tested on millions of lines of commercial C/C++ code and has been shown to meet the stringent criteria laid out by Lucent’s own software developers.}
}








@article{10.1145/3356579,
author = {Chen, Lin and Wu, Di and Ma, Wanwangying and Zhou, Yuming and Xu, Baowen and Leung, Hareton},
title = {How C++ Templates Are Used for Generic Programming: An Empirical Study on 50 Open Source Systems},
year = {2020},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3356579},
doi = {10.1145/3356579},
abstract = {Generic programming is a key paradigm for developing reusable software components. The inherent support for generic constructs is therefore important in programming languages. As for C++, the generic construct, templates, has been supported since the language was first released. However, little is currently known about how C++ templates are actually used in developing real software. In this study, we conduct an experiment to investigate the use of templates in practice. We analyze 1,267 historical revisions of 50 open source systems, consisting of 566 million lines of C++ code, to collect the data of the practical use of templates. We perform statistical analyses on the collected data and produce many interesting results. We uncover the following important findings: (1) templates are practically used to prevent code duplication, but this benefit is largely confined to a few highly used templates; (2) function templates do not effectively replace C-style generics, and developers with a C background do not show significant preference between the two language constructs; (3) developers seldom convert dynamic polymorphism to static polymorphism by using CRTP (Curiously Recursive Template Pattern); (4) the use of templates follows a power-law distribution in most cases, and C++ developers who prefer using templates are those without other language background; (5) C developer background seems to override C++ project guidelines. These findings are helpful not only for researchers to understand the tendency of template use but also for tool builders to implement better tools to support generic programming.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
articleno = {3},
numpages = {49},
keywords = {template, generic programming, empirical study, Programming language, C++}
}




@INPROCEEDINGS{713598,
  author={Yuan Wanghong and Chen Xiangkui and Xie Tao and Mei Hong and Yang Fuqing},
  booktitle={Proceedings Technology of Object-Oriented Languages. TOOLS 27 (Cat. No.98EX224)},
  title={C++ program information database for analysis tools},
  year={1998},
  volume={},
  number={},
  pages={173-180},
  keywords={Databases;Data analysis;Information analysis;Data mining;Information management;Software maintenance;Software engineering;Reverse engineering;Software testing;Joining processes},
  doi={10.1109/TOOLS.1998.713598}}




@inproceedings{10.1145/1409720.1409732,
author = {Telea, Alexandru and Voinea, Lucian},
title = {An interactive reverse engineering environment for large-scale C++ code},
year = {2008},
isbn = {9781605581125},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1409720.1409732},
doi = {10.1145/1409720.1409732},
abstract = {Few toolsets for reverse-engineering and understanding of C++ code provide parsing and fact extraction, querying, analysis and code metrics, navigation, and visualization of source-code-level facts in a way which is as easy-to-use as integrated development environments (IDEs) are for forward engineering. We present an interactive reverse-engineering environment (IRE) for C and C++ which allows to set up the fact extraction process, apply user-written queries and metrics, and visualize combined query results, metrics, code text, and code structure. Our IRE tightly couples a fast, tolerant C++ fact extractor, an open query system, and several scalable dense-pixel visualizations in a novel way, offering an easy way to analyze and examine large code bases. We illustrate our IRE with several examples, focusing on the added value of the integrated, visual reverse-engineering approach.},
booktitle = {Proceedings of the 4th ACM Symposium on Software Visualization},
pages = {67–76},
numpages = {10},
location = {Ammersee, Germany},
series = {SoftVis '08}
}


@article{https://doi.org/10.1002/smr.2605,
author = {Lucas, Walter and Carvalho, Fausto and Nunes, Rafael Campos and Bonifácio, Rodrigo and Saraiva, João and Accioly, Paola},
title = {Embracing modern C++ features: An empirical assessment on the KDE community},
journal = {Journal of Software: Evolution and Process},
volume = {36},
number = {5},
pages = {e2605},
keywords = {C++ programming language, language evolution, software rejuvenation},
doi = {https://doi.org/10.1002/smr.2605},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.2605},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/smr.2605},
abstract = {Abstract Similar to software systems, programming languages evolve substantially over time. Indeed, the community has more recently seen the release of new versions of mainstream languages in shorter and shorter time frames. For instance, the C++ working group has begun to release a new version of the language every 3 years, which now has a greater number of modern C++ features and improvements in modern standards (C++11, C++14, C++17, and C++ 20). Nonetheless, there is little empirical evidence on how developers are transitioning to use modern C++ constructs in legacy systems, and not understanding the trends and reasons for adopting these new modern C++ features might hinder software developers in conducting rejuvenation efforts. In this paper, we conduct an in-depth study to understand the development practices of KDE contributors to evolve their projects toward the use of modern C++ features. Our results show a trend in the widespread adoption of some modern C++ features (lambda expressions, auto-typed variables, and range-based for) in KDE community projects. We also found that developers in the KDE community are making large efforts to modernize their programs using automated tools, and we present some modernization scenarios and the benefits of adopting modern C++ features of the C++ programming language. Our results might help C++ software developers, in general, to evolve C++ legacy systems and tools builders to implement more effective tools that could help in rejuvenation efforts.},
year = {2024}
}


@article{BELAOUCHA20102075,
title = {FADAlib: an open source C++ library for fuzzy array dataflow analysis},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {2075-2084},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.232},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910002334},
author = {Marouane Belaoucha and Denis Barthou and Adrien Eliche and Sid-Ahmed-Ali Touati},
abstract = {Ubiquitous multicore architectures require that many levels of parallelism have to be found in codes. Dependence analysis is the main approach in compilers for the detection of parallelism. It enables vectorisation and automatic parallelisation, among many other optimising transformations, and is therefore of crucial importance for optimising compilers. This paper presents new open source software, FADAlib, performing an instance-wise dataflow analysis for scalar and array references. The software is a C++ implementation of the Fuzzy Array Dataflow Analysis (FADA) method. This method can be applied on codes with irregular control such as while-loops, if-then-else or non-regular array accesses, and computes exact instance-wise dataflow analysis on regular codes. As far as we know, FADAlib is the first released open source C++ implementation of instance-wise data flow dependence handling larger classes of programs. In addition, the library is technically independent from an existing compiler; It can be plugged in many of them; this article shows an example of a successful integration inside gcc/GRAPHITE. We give details concerning the library implementation and then report some initial results with gcc and possible use for trace scheduling on irregular codes.}
}


@article{https://doi.org/10.1002/spe.3082,
author = {Schuts, Mathijs T. W. and Aarssen, Rodin T. A. and Tielemans, Paul M. and Vinju, Jurgen J.},
title = {Large-scale semi-automated migration of legacy C/C++ test code},
journal = {Software: Practice and Experience},
volume = {52},
number = {7},
pages = {1543-1580},
keywords = {parsers, pattern matching, program analysis, refactoring, source code generation},
doi = {https://doi.org/10.1002/spe.3082},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.3082},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.3082},
abstract = {Abstract This is an industrial experience report on a large semi-automated migration of legacy test code in C and C++. The particular migration was enabled by automating most of the maintenance steps. Without automation this particular large-scale migration would not have been conducted, due to the risks involved in manual maintenance (risk of introducing errors, risk of unexpected rework, and loss of productivity). We describe and evaluate the method of automation we used on this real-world case. The benefits were that by automating analysis, we could make sure that we understand all the relevant details for the envisioned maintenance, without having to manually read and check our theories. Furthermore, by automating transformations we could reiterate and improve over complex and large scale source code updates, until they were “just right.” The drawbacks were that, first, we have had to learn new metaprogramming skills. Second, our automation scripts are not readily reusable for other contexts; they were necessarily developed for this ad-hoc maintenance task. Our analysis shows that automated software maintenance as compared to the (hypothetical) manual alternative method seems to be better both in terms of avoiding mistakes and avoiding rework because of such mistakes. It seems that necessary and beneficial source code maintenance need not to be avoided, if software engineers are enabled to create bespoke (and ad-hoc) analysis and transformation tools to support it.},
year = {2022}
}


@InProceedings{10.1007/978-3-662-49498-1_25,
author="Schuster, Christopher
and Disney, Tim
and Flanagan, Cormac",
editor="Thiemann, Peter",
title="Macrofication: Refactoring by Reverse Macro Expansion",
booktitle="Programming Languages and Systems",
year="2016",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="644--671",
abstract="Refactoring is a code transformation performed at development time that improves the quality of code while preserving its observable behavior. Macro expansion is also a code transformation, but performed at compile time, that replaces instances of macro invocation patterns with the corresponding macro body or template. The key insight of this paper is that for each pattern-template macro, we can automatically generate a corresponding refactoring tool that finds complex code fragments matching the macro template and replaces them with the equivalent but simpler macro invocation pattern; we call this novel refactoring process macrofication.",
isbn="978-3-662-49498-1"
}


@INPROCEEDINGS{8836193,
  author={Gabor, Ulrich Thomas and Siegert, Daniel Ferdinand and Spinczyk, Olaf},
  booktitle={ARCS Workshop 2019; 32nd International Conference on Architecture of Computing Systems},
  title={Software-Fault Injection in Source Code with Clang},
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={Injection of software faults into source code is one promising approach to improve software fault tolerance and assess the dependability of software systems. While multiple approaches have been presented in the past, there is still room for improvement regarding the accuracy of the injections in comparison to the fault model. We propose an approach specifically for C++ based on the Clang ASTMatchFinder functionality, which is currently in development, but already leads to promising results regarding the accuracy of generated injections.},
  keywords={},
  doi={},
  ISSN={},
  month={May},
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% I haven't yet read the following articles.
%%%


@InProceedings{favre:97,
  author =       "Jean-Marie Favre",
  title =        "{CPP} Denotational Semantics and its Application to
                 Software Maintenance",
  booktitle =    "1st Euromicro Working Conference on Software
                 Maintenance and Reengineering CSMR 97",
  month =        mar,
  year =         "1997",
  publisher =    "IEEE Computer Society Press",
  abstract =     "Very often, portability of large software products is
                 achieved via the empirical use of old tools like CPP,
                 the preprocessor of the C language. Though powerful low
                 level features like conditional compilation cause
                 serious maintenance problems. There is a lack of
                 adequate tools to support such activities. This paper
                 presents our approach to this problem. We introduce
                 APP, an abstract language semantically equivalent to
                 CPP but based on traditional programming-in-the-small
                 concepts. A rigorous description of the semantics of
                 this language makes it possible to develop reliable
                 reverse engineering tools.",
  class =        "Reverse_Engineering, Reverse_Design,
                 Configuration_Structures",
  sender =       "antonio@ifi.unizh.ch",
}




















@InProceedings{LivadasS94,
  author = 	 "Panos E. Livadas and David T. Small",
  title = 	 "Understanding code containing preprocessor constructs",
  booktitle = 	 "IEEE Third Workshop on Program Comprehension",
  year =	 1994,
  address =	 "Washington, DC, USA",
  month =	 nov # "~14--15,",
  pages =	 "89--97"
}


@Article{ABACUS89,
  key =          "Abacus",
  author =       "A. Abacus",
  title =        "Parameterizing {C} Code at Compile and Run Time",
  journal =      "Structured Programming",
  publisher =    "Springer-Verlag",
  volume =       "10",
  number =       "4",
  year =         "1989",
  pages =        "209--214",
  keywords =     "parameterization; C; debugging; imbedded debugging
                 code; C preprocessor",
  abstract =     "This paper describes a convenient mechanism for
                 imbedding debugging code within the source code of
                 programs written in C. Debugging code can be packaged
                 into any number of functionally independent debugging
                 units. Conditional compilation of each unit is
                 controlled by a separate compile time switch. Execution
                 of each compiled unit is controlled by a separate run
                 time switch. Efficient final products can be generated
                 by turning off compile time switches of all debugging
                 units. This packaging method depends on the C
                 preprocessor and its final refinement depends on the
                 ability of the compiler to perform 'dead code removal'
                 optimization. Each routine or a family of related
                 routines can be parameterized independently of other
                 routines. Run time options of library routines can be
                 changed without access to their source code. This
                 parameterization is not restricted to debugging code.
                 The same mechanism may be used to select one of several
                 implementations of a feature, or to set initial values
                 of variables.",
  bibdate =      "Tue Nov 7 08:25:39 1989",
  owner =        "robyn",
}


@Article{Mudd:1990:ACD,
  author =       "John Mudd",
  title =        "Automating {C} Debugging with Preprocessor Macros",
  journal =      "Computer Language Magazine",
  volume =       "7",
  number =       "2",
  pages =        "69--??",
  month =        feb,
  year =         "1990",
  coden =        "COMLEF",
  ISSN =         "0749-2839",
  bibdate =      "Tue Jan 23 08:04:25 MST 1996",
  acknowledgement = ack-nhfb,
}


@Article{Allison:1994:P,
  author =       "Chuck Allison",
  title =        "The Preprocessor",
  journal =      "C Users Journal",
  volume =       "12",
  type =         "Code Capsules",
  number =       "3",
  pages =        "101--??",
  month =        mar,
  year =         "1994",
  ISSN =         "0898-9788",
  bibdate =      "Fri Aug 30 16:52:23 MDT 1996",
  acknowledgement = ack-nhfb,
}


%% These resulted from an online search for "Cpp"


@Article{Parks:JCLT-2-3-194,
  author =       "John H. Parks",
  title =        "Case Study: Building an {ANSI CPP}",
  journal =      "The Journal of {C} Language Translation",
  volume =       "2",
  number =       "3",
  pages =        "194--206",
  month =        dec,
  year =         "1990",
  ISSN =         "1042-5721",
  bibdate =      "Fri Nov 21 15:06:25 1997",
  acknowledgement = ack-nhfb,
  remark =       "A thorough look at the issues involved in building an
                 ideal preprocessor that can be user-configurable to
                 support ANSI C and most common extensions.",
}


@Article{Hazard:1991:UCA,
  author =       "William P. Hazard",
  title =        "Using cpp to Aid Portability",
  journal =      "Computer Language Magazine",
  volume =       "8",
  number =       "11",
  pages =        "49--??",
  month =        nov,
  year =         "1991",
  coden =        "COMLEF",
  ISSN =         "0749-2839",
  bibdate =      "Tue Jan 23 08:04:25 MST 1996",
  acknowledgement = ack-nhfb,
}


@InProceedings{Locanthi:1987:FBA,
  author =       "Bart N. Locanthi",
  title =        "Fast bitblt() with asm() and cpp",
  editor =       "{USENIX Association}",
  booktitle =    "{EUUG} Conference Proceedings, Autumn, 1987. Dublin,
                 Ireland",
  publisher =    "EUUG",
  address =      "Buntingford, Herts, UK",
  month =        "Autumn",
  year =         "1987",
  pages =        "243--259",
  bibdate =      "Tue Feb 20 15:42:13 MST 1996",
  acknowledgement = ack-nhfb,
  affiliation =  "AT\&T Bell Laboratories, Murray Hill",
}


@Article{Ream:1990:CCV,
  author =       "Edward K. Ream",
  title =        "{CUG319 CPP v5.3}",
  journal =      "C Users Journal",
  volume =       "8",
  type =         "CUG New Release",
  number =       "7",
  pages =        "111--??",
  month =        jul,
  year =         "1990",
  ISSN =         "0898-9788",
  bibdate =      "Fri Aug 30 16:52:23 MDT 1996",
  acknowledgement = ack-nhfb,
}




@Manual{Scwm,
  title = 	 "Scwm Reference Manual:  The Authoritative Guide to the {E}macs of Window Managers",
  author =	 "Maciej Stachowiak and Greg J. Badros",
  year =	 1999,
  note =	 "http://vicarious-existence.mit.edu/scwm/"
}




% LocalWords: TechReport ellemtel inline InProceedings McCloskeyB FSE
% LocalWords: McCloskey ASTEC booktitle addr MACROSCOPE ASTEC's al CPP
% LocalWords: analyzability refactorability OpenSSH args ASTs ifdef
% LocalWords: Macroscope ASTLOG
